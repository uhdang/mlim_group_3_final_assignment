{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/uhdang/mlim_group_3_final_assignment/blob/main/project/train_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZmdD9ENz1rI"
   },
   "source": [
    "TODO:\n",
    "\n",
    "- Downsample training set (reduce method to delete irrelevant rows)\n",
    "- maybe PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaaoayvlsm9G"
   },
   "source": [
    "# Google Colab Runtime\n",
    "Run if using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86i45kEfms5D",
    "outputId": "763b3965-8780-4417-bbd3-888ac171634c"
   },
   "outputs": [],
   "source": [
    "# # # import pandas as pd\n",
    "# # # \n",
    "# # import numpy as np# \n",
    "# # \n",
    "# import o# s# \n",
    "# \n",
    "# from google.colab import dri# v# e# \n",
    "# \n",
    "# import # s# y# s#\n",
    "# drive.mount('/content/dri# v# e# '# )\n",
    "# sys.path.append('/content/drive/My Drive/My Dri# v# e# '# )\n",
    "#\n",
    "# from dataloader import Dat# a# l# o# ader\n",
    "# # L# o# a# d#  Data\n",
    "# path = \"/content/drive/MyDrive/My Drive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psMpyT8ssu6E"
   },
   "source": [
    "# Local Runtime\n",
    "Run if using notebook locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XgbVDmxCmYc_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import optuna.integration.lightgbm as lightgb\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from dataloader import Dataloader\n",
    "from dataloader import create_combined_dict\n",
    "\n",
    "\n",
    "# Load Data\n",
    "path = os.getcwd() + \"/../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STbPksO71J4p"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d1xFPV6hneM7"
   },
   "outputs": [],
   "source": [
    "# load data which creates baskets and coupons\n",
    "data = Dataloader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gWGa7Or_npeD"
   },
   "outputs": [],
   "source": [
    "# Create Categories before CV as they don't change and consume time otherwise\n",
    "data.create_category_table(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O3VhVltOnwRD"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "weeks = [86, 87, 88, 89]\n",
    "shopper_list = list(range(2000))\n",
    "shopper_chunks = [shopper_list[i:i + 100] for i in range(0, len(shopper_list), 100)]\n",
    "\n",
    "cv_dict = {\n",
    "    'X_train': list(),\n",
    "    'y_train': list(),\n",
    "    'X_test': list(),\n",
    "    'y_test': list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [45:12<00:00, 135.60s/it]\n",
      "100%|██████████| 20/20 [46:07<00:00, 138.35s/it]\n",
      "100%|██████████| 20/20 [49:53<00:00, 149.69s/it] \n",
      "100%|██████████| 20/20 [49:15<00:00, 147.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week: 86\n",
      "week: 87\n",
      "week: 88\n",
      "week: 89\n"
     ]
    }
   ],
   "source": [
    "for i, week in enumerate(weeks):\n",
    "  print(f\"week: {week}\")\n",
    "\n",
    "  X_train_list = list()\n",
    "  y_train_list = list()\n",
    "  X_test_list = list()\n",
    "  y_test_list = list()\n",
    "\n",
    "  for idx, shopper in enumerate(tqdm(shopper_chunks)):\n",
    "      # print(f\"shopper_chunk index: {idx}\")\n",
    "\n",
    "      # train-test-split\n",
    "      data.train_test_split(week, shopper)\n",
    "\n",
    "      # data add categories\n",
    "      data.add_categories()\n",
    "\n",
    "      # create features\n",
    "      data.create_feature_dict()\n",
    "\n",
    "      # combine everything\n",
    "      if i == 0:\n",
    "          X_train, y_train, X_test, y_test = data.make_featured_data()\n",
    "          X_train_list.append(X_train)\n",
    "          y_train_list.append(y_train)\n",
    "          del X_train, y_train\n",
    "      else:\n",
    "          _, _, X_test, y_test = data.make_featured_data()\n",
    "\n",
    "      X_test_list.append(X_test)\n",
    "      y_test_list.append(y_test)\n",
    "      del X_test, y_test\n",
    "\n",
    "  cv_dict = create_combined_dict(X_train_list, y_train_list, X_test_list, y_test_list, cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('cv_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(cv_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [40:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('dataloader.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts4lbT47sQdO",
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hAJ0GTc_sep6"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.2.0'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def downsample(df, y):\n",
    "  df_target_coupon = df.loc[(y==1) | (df['coupon']=='Yes')]\n",
    "  y_target_coupon = y.loc[(y==1) | (df['coupon']=='Yes')]\n",
    "  df_down = df.loc[(y==0) & (df['coupon']=='No')]\n",
    "  y_down = y.loc[(y==0) & (df[\"coupon\"]==\"No\")]\n",
    "  df_down, y_down = resample(\n",
    "      df_down,\n",
    "      y_down,\n",
    "      replace=False,\n",
    "      n_samples=df_target_coupon.shape[0],\n",
    "      stratify=df_down['shopper']\n",
    "  )\n",
    "  df_all = pd.concat([df_target_coupon, df_down], ignore_index=True)\n",
    "  y_all = pd.concat([y_target_coupon, y_down], ignore_index=True)\n",
    "\n",
    "  return df_all, y_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dtrain = lightgb.Dataset(cv_dict['X_train'][0], label=cv_dict['y_train'][0])\n",
    "X_test0, y_test0 = downsample(cv_dict['X_test'][0], cv_dict['y_test'][0])\n",
    "dval0 = lightgb.Dataset(X_test0, label=y_test0)\n",
    "X_test1, y_test1 = downsample(cv_dict['X_test'][1], cv_dict['y_test'][1])\n",
    "dval1 = lightgb.Dataset(X_test1, label=y_test1)\n",
    "X_test2, y_test2 = downsample(cv_dict['X_test'][2], cv_dict['y_test'][2])\n",
    "dval2 = lightgb.Dataset(X_test2, label=y_test2)\n",
    "X_test3, y_test3 = downsample(cv_dict['X_test'][3], cv_dict['y_test'][3])\n",
    "dval3 = lightgb.Dataset(X_test3, label=y_test3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-03-20 23:48:20,066]\u001B[0m A new study created in memory with name: no-name-4eeefd92-ea17-42df-bd3b-e16f6575899d\u001B[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\uh_da\\anaconda3\\envs\\hu-mlim\\lib\\site-packages\\lightgbm\\basic.py:1161: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['category', 'coupon', 'coupon_in_same_category', 'product', 'shopper']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\uh_da\\anaconda3\\envs\\hu-mlim\\lib\\site-packages\\lightgbm\\basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n",
      "feature_fraction, val_score: 0.259041:  14%|#4        | 1/7 [02:47<16:44, 167.49s/it]\u001B[32m[I 2021-03-20 23:51:07,696]\u001B[0m Trial 0 finished with value: 0.259041076776342 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.259041076776342.\u001B[0m\n",
      "feature_fraction, val_score: 0.259041:  29%|##8       | 2/7 [06:02<15:18, 183.72s/it]\u001B[32m[I 2021-03-20 23:54:22,785]\u001B[0m Trial 1 finished with value: 0.2604038408742749 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.259041076776342.\u001B[0m\n",
      "feature_fraction, val_score: 0.254452:  43%|####2     | 3/7 [08:50<11:46, 176.60s/it]\u001B[32m[I 2021-03-20 23:57:10,920]\u001B[0m Trial 2 finished with value: 0.25445200938376644 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.25445200938376644.\u001B[0m\n",
      "feature_fraction, val_score: 0.253251:  57%|#####7    | 4/7 [11:07<08:03, 161.00s/it]\u001B[32m[I 2021-03-20 23:59:28,007]\u001B[0m Trial 3 finished with value: 0.25325145216798445 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.25325145216798445.\u001B[0m\n",
      "feature_fraction, val_score: 0.253251:  71%|#######1  | 5/7 [14:35<05:55, 177.95s/it]\u001B[32m[I 2021-03-21 00:02:56,009]\u001B[0m Trial 4 finished with value: 0.2630502288343461 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.25325145216798445.\u001B[0m\n",
      "feature_fraction, val_score: 0.253251:  86%|########5 | 6/7 [17:26<02:55, 175.60s/it]\u001B[32m[I 2021-03-21 00:05:47,039]\u001B[0m Trial 5 finished with value: 0.25645467019577384 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.25325145216798445.\u001B[0m\n",
      "feature_fraction, val_score: 0.253251: 100%|##########| 7/7 [20:44<00:00, 182.79s/it]\u001B[32m[I 2021-03-21 00:09:04,625]\u001B[0m Trial 6 finished with value: 0.26112548829998444 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.25325145216798445.\u001B[0m\n",
      "feature_fraction, val_score: 0.253251: 100%|##########| 7/7 [20:44<00:00, 177.79s/it]\n",
      "num_leaves, val_score: 0.253251:   5%|5         | 1/20 [03:27<1:05:39, 207.35s/it]\u001B[32m[I 2021-03-21 00:12:32,104]\u001B[0m Trial 7 finished with value: 0.2537150054233634 and parameters: {'num_leaves': 219}. Best is trial 7 with value: 0.2537150054233634.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  10%|#         | 2/20 [06:29<57:49, 192.75s/it]  \u001B[32m[I 2021-03-21 00:15:34,655]\u001B[0m Trial 8 finished with value: 0.25358498696977577 and parameters: {'num_leaves': 106}. Best is trial 8 with value: 0.25358498696977577.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  15%|#5        | 3/20 [09:20<51:41, 182.45s/it]\u001B[32m[I 2021-03-21 00:18:24,830]\u001B[0m Trial 9 finished with value: 0.2535192409123593 and parameters: {'num_leaves': 100}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  20%|##        | 4/20 [12:05<46:52, 175.77s/it]\u001B[32m[I 2021-03-21 00:21:10,344]\u001B[0m Trial 10 finished with value: 0.2535604551011841 and parameters: {'num_leaves': 102}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  25%|##5       | 5/20 [15:23<45:58, 183.88s/it]\u001B[32m[I 2021-03-21 00:24:28,624]\u001B[0m Trial 11 finished with value: 0.2537347984483195 and parameters: {'num_leaves': 206}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  30%|###       | 6/20 [19:00<45:29, 194.98s/it]\u001B[32m[I 2021-03-21 00:28:05,131]\u001B[0m Trial 12 finished with value: 0.25365778337719735 and parameters: {'num_leaves': 239}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  35%|###5      | 7/20 [22:20<42:36, 196.69s/it]\u001B[32m[I 2021-03-21 00:31:25,353]\u001B[0m Trial 13 finished with value: 0.2536761178810624 and parameters: {'num_leaves': 221}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  40%|####      | 8/20 [25:42<39:40, 198.36s/it]\u001B[32m[I 2021-03-21 00:34:47,294]\u001B[0m Trial 14 finished with value: 0.2536339356473423 and parameters: {'num_leaves': 246}. Best is trial 9 with value: 0.2535192409123593.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  45%|####5     | 9/20 [28:27<34:28, 188.03s/it]\u001B[32m[I 2021-03-21 00:37:32,611]\u001B[0m Trial 15 finished with value: 0.25336853100068996 and parameters: {'num_leaves': 91}. Best is trial 15 with value: 0.25336853100068996.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  50%|#####     | 10/20 [31:41<31:36, 189.68s/it]\u001B[32m[I 2021-03-21 00:40:45,986]\u001B[0m Trial 16 finished with value: 0.2536780713597408 and parameters: {'num_leaves': 189}. Best is trial 15 with value: 0.25336853100068996.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  55%|#####5    | 11/20 [34:59<28:51, 192.43s/it]\u001B[32m[I 2021-03-21 00:44:04,641]\u001B[0m Trial 17 finished with value: 0.2536650001638631 and parameters: {'num_leaves': 157}. Best is trial 15 with value: 0.25336853100068996.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  60%|######    | 12/20 [37:09<23:07, 173.44s/it]\u001B[32m[I 2021-03-21 00:46:14,653]\u001B[0m Trial 18 finished with value: 0.2533726339388394 and parameters: {'num_leaves': 26}. Best is trial 15 with value: 0.25336853100068996.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  65%|######5   | 13/20 [39:13<18:28, 158.41s/it]\u001B[32m[I 2021-03-21 00:48:18,475]\u001B[0m Trial 19 finished with value: 0.2534289595167274 and parameters: {'num_leaves': 18}. Best is trial 15 with value: 0.25336853100068996.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  70%|#######   | 14/20 [41:35<15:20, 153.47s/it]\u001B[32m[I 2021-03-21 00:50:40,515]\u001B[0m Trial 20 finished with value: 0.2532577286386207 and parameters: {'num_leaves': 29}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  75%|#######5  | 15/20 [44:08<12:46, 153.36s/it]\u001B[32m[I 2021-03-21 00:53:13,656]\u001B[0m Trial 21 finished with value: 0.25335827188465654 and parameters: {'num_leaves': 57}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  80%|########  | 16/20 [46:32<10:01, 150.40s/it]\u001B[32m[I 2021-03-21 00:55:37,153]\u001B[0m Trial 22 finished with value: 0.25339829623071897 and parameters: {'num_leaves': 55}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  85%|########5 | 17/20 [49:02<07:30, 150.27s/it]\u001B[32m[I 2021-03-21 00:58:07,129]\u001B[0m Trial 23 finished with value: 0.2534326608438551 and parameters: {'num_leaves': 56}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  90%|######### | 18/20 [51:28<04:58, 149.11s/it]\u001B[32m[I 2021-03-21 01:00:33,529]\u001B[0m Trial 24 finished with value: 0.2534326608438551 and parameters: {'num_leaves': 56}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253251:  95%|#########5| 19/20 [53:13<02:15, 135.72s/it]\u001B[32m[I 2021-03-21 01:02:18,076]\u001B[0m Trial 25 finished with value: 0.25393796454577244 and parameters: {'num_leaves': 5}. Best is trial 20 with value: 0.2532577286386207.\u001B[0m\n",
      "num_leaves, val_score: 0.253194: 100%|##########| 20/20 [55:25<00:00, 134.72s/it]\u001B[32m[I 2021-03-21 01:04:30,467]\u001B[0m Trial 26 finished with value: 0.25319425942432944 and parameters: {'num_leaves': 37}. Best is trial 26 with value: 0.25319425942432944.\u001B[0m\n",
      "num_leaves, val_score: 0.253194: 100%|##########| 20/20 [55:25<00:00, 166.29s/it]\n",
      "bagging, val_score: 0.253131:  10%|#         | 1/10 [01:55<17:23, 115.94s/it]\u001B[32m[I 2021-03-21 01:06:26,543]\u001B[0m Trial 27 finished with value: 0.25313112055248377 and parameters: {'bagging_fraction': 0.6190040709189294, 'bagging_freq': 5}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  20%|##        | 2/10 [03:49<15:15, 114.38s/it]\u001B[32m[I 2021-03-21 01:08:19,836]\u001B[0m Trial 28 finished with value: 0.2533840693638183 and parameters: {'bagging_fraction': 0.5026257240259104, 'bagging_freq': 2}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  30%|###       | 3/10 [06:11<14:48, 126.98s/it]\u001B[32m[I 2021-03-21 01:10:41,801]\u001B[0m Trial 29 finished with value: 0.25317018119912643 and parameters: {'bagging_fraction': 0.7961264757274112, 'bagging_freq': 4}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  40%|####      | 4/10 [08:22<12:52, 128.70s/it]\u001B[32m[I 2021-03-21 01:12:53,131]\u001B[0m Trial 30 finished with value: 0.2531559325350347 and parameters: {'bagging_fraction': 0.7490323331117874, 'bagging_freq': 4}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  50%|#####     | 5/10 [10:59<11:35, 139.07s/it]\u001B[32m[I 2021-03-21 01:15:30,598]\u001B[0m Trial 31 finished with value: 0.2532277190553908 and parameters: {'bagging_fraction': 0.9258225618009568, 'bagging_freq': 6}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  60%|######    | 6/10 [13:06<08:59, 134.85s/it]\u001B[32m[I 2021-03-21 01:17:37,238]\u001B[0m Trial 32 finished with value: 0.25327121249887924 and parameters: {'bagging_fraction': 0.670671586432037, 'bagging_freq': 6}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  70%|#######   | 7/10 [14:47<06:11, 123.76s/it]\u001B[32m[I 2021-03-21 01:19:18,195]\u001B[0m Trial 33 finished with value: 0.25339938815879215 and parameters: {'bagging_fraction': 0.4421595639771925, 'bagging_freq': 3}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  80%|########  | 8/10 [16:40<04:00, 120.28s/it]\u001B[32m[I 2021-03-21 01:21:11,016]\u001B[0m Trial 34 finished with value: 0.2532860471048358 and parameters: {'bagging_fraction': 0.6091506612842756, 'bagging_freq': 6}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131:  90%|######### | 9/10 [18:46<02:02, 122.13s/it]\u001B[32m[I 2021-03-21 01:23:17,199]\u001B[0m Trial 35 finished with value: 0.2534645474025916 and parameters: {'bagging_fraction': 0.48176057102163244, 'bagging_freq': 1}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131: 100%|##########| 10/10 [21:03<00:00, 126.60s/it]\u001B[32m[I 2021-03-21 01:25:33,833]\u001B[0m Trial 36 finished with value: 0.25319813028529 and parameters: {'bagging_fraction': 0.7739824370121449, 'bagging_freq': 3}. Best is trial 27 with value: 0.25313112055248377.\u001B[0m\n",
      "bagging, val_score: 0.253131: 100%|##########| 10/10 [21:03<00:00, 126.34s/it]\n",
      "feature_fraction_stage2, val_score: 0.253131:  33%|###3      | 1/3 [01:54<03:48, 114.43s/it]\u001B[32m[I 2021-03-21 01:27:28,405]\u001B[0m Trial 37 finished with value: 0.25389219235584254 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.25389219235584254.\u001B[0m\n",
      "feature_fraction_stage2, val_score: 0.253131:  67%|######6   | 2/3 [03:51<01:55, 115.99s/it]\u001B[32m[I 2021-03-21 01:29:25,479]\u001B[0m Trial 38 finished with value: 0.2540125918848224 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.25389219235584254.\u001B[0m\n",
      "feature_fraction_stage2, val_score: 0.253131: 100%|##########| 3/3 [05:51<00:00, 117.77s/it]\u001B[32m[I 2021-03-21 01:31:25,365]\u001B[0m Trial 39 finished with value: 0.253793760129484 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 39 with value: 0.253793760129484.\u001B[0m\n",
      "feature_fraction_stage2, val_score: 0.253131: 100%|##########| 3/3 [05:51<00:00, 117.17s/it]\n",
      "regularization_factors, val_score: 0.253131:   5%|5         | 1/20 [01:54<36:24, 114.97s/it]\u001B[32m[I 2021-03-21 01:33:20,468]\u001B[0m Trial 40 finished with value: 0.25313108924671185 and parameters: {'lambda_l1': 6.437313046511468e-08, 'lambda_l2': 0.009866025078441022}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  10%|#         | 2/20 [03:49<34:22, 114.59s/it]\u001B[32m[I 2021-03-21 01:35:14,789]\u001B[0m Trial 41 finished with value: 0.25313111915627623 and parameters: {'lambda_l1': 4.1123441946897774e-07, 'lambda_l2': 0.0004351051026441945}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  15%|#5        | 3/20 [05:43<32:28, 114.61s/it]\u001B[32m[I 2021-03-21 01:37:09,418]\u001B[0m Trial 42 finished with value: 0.25313111694210855 and parameters: {'lambda_l1': 0.002318049061029085, 'lambda_l2': 3.4536034046524393e-06}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  20%|##        | 4/20 [07:40<30:45, 115.34s/it]\u001B[32m[I 2021-03-21 01:39:05,889]\u001B[0m Trial 43 finished with value: 0.25318614693635455 and parameters: {'lambda_l1': 0.0008637552967500595, 'lambda_l2': 0.9249851995507279}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  25%|##5       | 5/20 [09:34<28:42, 114.84s/it]\u001B[32m[I 2021-03-21 01:40:59,833]\u001B[0m Trial 44 finished with value: 0.2531311205520727 and parameters: {'lambda_l1': 1.9440168432100317e-08, 'lambda_l2': 5.5544743715356315e-08}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  30%|###       | 6/20 [11:28<26:43, 114.54s/it]\u001B[32m[I 2021-03-21 01:42:53,797]\u001B[0m Trial 45 finished with value: 0.2531311136686637 and parameters: {'lambda_l1': 0.002819656145919369, 'lambda_l2': 0.0007934052848727905}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  35%|###5      | 7/20 [13:20<24:40, 113.88s/it]\u001B[32m[I 2021-03-21 01:44:46,327]\u001B[0m Trial 46 finished with value: 0.25319958019386263 and parameters: {'lambda_l1': 0.01879442283814993, 'lambda_l2': 0.4984329287704524}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  40%|####      | 8/20 [15:15<22:49, 114.13s/it]\u001B[32m[I 2021-03-21 01:46:40,978]\u001B[0m Trial 47 finished with value: 0.2531311205489786 and parameters: {'lambda_l1': 1.3072922079578225e-06, 'lambda_l2': 1.5615320175336727e-07}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  45%|####5     | 9/20 [17:09<20:53, 113.95s/it]\u001B[32m[I 2021-03-21 01:48:34,542]\u001B[0m Trial 48 finished with value: 0.2531863367795306 and parameters: {'lambda_l1': 6.506743274272075e-07, 'lambda_l2': 0.8679863910415692}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  50%|#####     | 10/20 [19:01<18:55, 113.56s/it]\u001B[32m[I 2021-03-21 01:50:27,211]\u001B[0m Trial 49 finished with value: 0.2531522135788513 and parameters: {'lambda_l1': 0.306568809312649, 'lambda_l2': 7.00978461664168e-08}. Best is trial 40 with value: 0.25313108924671185.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  55%|#####5    | 11/20 [20:54<16:59, 113.30s/it]\u001B[32m[I 2021-03-21 01:52:19,936]\u001B[0m Trial 50 finished with value: 0.25313106942170327 and parameters: {'lambda_l1': 1.547157734210918e-05, 'lambda_l2': 0.016094233832795436}. Best is trial 50 with value: 0.25313106942170327.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  60%|######    | 12/20 [22:47<15:05, 113.20s/it]\u001B[32m[I 2021-03-21 01:54:12,895]\u001B[0m Trial 51 finished with value: 0.25313108480489716 and parameters: {'lambda_l1': 2.1935905532495836e-05, 'lambda_l2': 0.011246152324540489}. Best is trial 50 with value: 0.25313106942170327.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  65%|######5   | 13/20 [24:40<13:13, 113.29s/it]\u001B[32m[I 2021-03-21 01:56:06,391]\u001B[0m Trial 52 finished with value: 0.2531310381470335 and parameters: {'lambda_l1': 1.7386709009014455e-05, 'lambda_l2': 0.02593068110353129}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  70%|#######   | 14/20 [26:34<11:20, 113.47s/it]\u001B[32m[I 2021-03-21 01:58:00,299]\u001B[0m Trial 53 finished with value: 0.2531310782259282 and parameters: {'lambda_l1': 5.448246436630644e-05, 'lambda_l2': 0.013306867210800566}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  75%|#######5  | 15/20 [28:26<09:25, 113.08s/it]\u001B[32m[I 2021-03-21 01:59:52,455]\u001B[0m Trial 54 finished with value: 0.25313112041006747 and parameters: {'lambda_l1': 1.6935235270880875e-05, 'lambda_l2': 3.673570381771479e-05}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  80%|########  | 16/20 [30:22<07:35, 113.79s/it]\u001B[32m[I 2021-03-21 02:01:47,900]\u001B[0m Trial 55 finished with value: 0.2531536485027927 and parameters: {'lambda_l1': 0.00012118102466236405, 'lambda_l2': 0.11493476897713102}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  85%|########5 | 17/20 [32:14<05:39, 113.28s/it]\u001B[32m[I 2021-03-21 02:03:39,986]\u001B[0m Trial 56 finished with value: 0.2531680862655047 and parameters: {'lambda_l1': 3.5312472452982152e-06, 'lambda_l2': 4.150072743171296}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  90%|######### | 18/20 [34:05<03:45, 112.52s/it]\u001B[32m[I 2021-03-21 02:05:30,732]\u001B[0m Trial 57 finished with value: 0.25313194853806487 and parameters: {'lambda_l1': 6.0770050149567085, 'lambda_l2': 0.06846694790147867}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253131:  95%|#########5| 19/20 [35:59<01:53, 113.02s/it]\u001B[32m[I 2021-03-21 02:07:24,937]\u001B[0m Trial 58 finished with value: 0.2531311204703807 and parameters: {'lambda_l1': 9.788737795307378e-08, 'lambda_l2': 2.3894786059812817e-05}. Best is trial 52 with value: 0.2531310381470335.\u001B[0m\n",
      "regularization_factors, val_score: 0.253092: 100%|##########| 20/20 [37:53<00:00, 113.46s/it]\u001B[32m[I 2021-03-21 02:09:19,431]\u001B[0m Trial 59 finished with value: 0.2530917844394891 and parameters: {'lambda_l1': 5.024548095870188e-06, 'lambda_l2': 7.715874633155568}. Best is trial 59 with value: 0.2530917844394891.\u001B[0m\n",
      "regularization_factors, val_score: 0.253092: 100%|##########| 20/20 [37:54<00:00, 113.70s/it]\n",
      "min_data_in_leaf, val_score: 0.253092:  20%|##        | 1/5 [01:52<07:31, 112.87s/it]\u001B[32m[I 2021-03-21 02:11:12,424]\u001B[0m Trial 60 finished with value: 0.2530917844394891 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.2530917844394891.\u001B[0m\n",
      "min_data_in_leaf, val_score: 0.253092:  40%|####      | 2/5 [03:44<05:36, 112.09s/it]\u001B[32m[I 2021-03-21 02:13:03,967]\u001B[0m Trial 61 finished with value: 0.2530917844394891 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.2530917844394891.\u001B[0m\n",
      "min_data_in_leaf, val_score: 0.253092:  60%|######    | 3/5 [05:37<03:45, 112.53s/it]\u001B[32m[I 2021-03-21 02:14:57,017]\u001B[0m Trial 62 finished with value: 0.2530917844394891 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.2530917844394891.\u001B[0m\n",
      "min_data_in_leaf, val_score: 0.253092:  80%|########  | 4/5 [07:29<01:52, 112.32s/it]\u001B[32m[I 2021-03-21 02:16:49,017]\u001B[0m Trial 63 finished with value: 0.2530917844394891 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.2530917844394891.\u001B[0m\n",
      "min_data_in_leaf, val_score: 0.253092: 100%|##########| 5/5 [09:21<00:00, 112.12s/it]\u001B[32m[I 2021-03-21 02:18:40,779]\u001B[0m Trial 64 finished with value: 0.2530917844394891 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.2530917844394891.\u001B[0m\n",
      "min_data_in_leaf, val_score: 0.253092: 100%|##########| 5/5 [09:21<00:00, 112.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.312626\tvalid_1's binary_logloss: 0.312025\tvalid_2's binary_logloss: 0.317081\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.257873\tvalid_1's binary_logloss: 0.258659\tvalid_2's binary_logloss: 0.259041\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.315205\tvalid_1's binary_logloss: 0.31444\tvalid_2's binary_logloss: 0.31956\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.25931\tvalid_1's binary_logloss: 0.260424\tvalid_2's binary_logloss: 0.260404\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.290617\tvalid_1's binary_logloss: 0.29108\tvalid_2's binary_logloss: 0.293652\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's binary_logloss: 0.253532\tvalid_1's binary_logloss: 0.253969\tvalid_2's binary_logloss: 0.254452\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283113\tvalid_1's binary_logloss: 0.283529\tvalid_2's binary_logloss: 0.285866\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252595\tvalid_1's binary_logloss: 0.252688\tvalid_2's binary_logloss: 0.253251\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.325619\tvalid_1's binary_logloss: 0.323544\tvalid_2's binary_logloss: 0.329949\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.261797\tvalid_1's binary_logloss: 0.262876\tvalid_2's binary_logloss: 0.26305\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.30445\tvalid_1's binary_logloss: 0.304328\tvalid_2's binary_logloss: 0.308463\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.255581\tvalid_1's binary_logloss: 0.256061\tvalid_2's binary_logloss: 0.256455\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.318812\tvalid_1's binary_logloss: 0.317263\tvalid_2's binary_logloss: 0.323016\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.259944\tvalid_1's binary_logloss: 0.261006\tvalid_2's binary_logloss: 0.261125\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.28601\tvalid_1's binary_logloss: 0.286944\tvalid_2's binary_logloss: 0.289657\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252616\tvalid_1's binary_logloss: 0.252989\tvalid_2's binary_logloss: 0.253715\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284763\tvalid_1's binary_logloss: 0.285665\tvalid_2's binary_logloss: 0.288342\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252565\tvalid_1's binary_logloss: 0.252976\tvalid_2's binary_logloss: 0.253585\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.28486\tvalid_1's binary_logloss: 0.285787\tvalid_2's binary_logloss: 0.288451\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252556\tvalid_1's binary_logloss: 0.253004\tvalid_2's binary_logloss: 0.253519\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285078\tvalid_1's binary_logloss: 0.285954\tvalid_2's binary_logloss: 0.288371\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252584\tvalid_1's binary_logloss: 0.253032\tvalid_2's binary_logloss: 0.25356\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285549\tvalid_1's binary_logloss: 0.286742\tvalid_2's binary_logloss: 0.289299\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.25257\tvalid_1's binary_logloss: 0.253063\tvalid_2's binary_logloss: 0.253735\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.286031\tvalid_1's binary_logloss: 0.286946\tvalid_2's binary_logloss: 0.289679\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252602\tvalid_1's binary_logloss: 0.252989\tvalid_2's binary_logloss: 0.253658\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285915\tvalid_1's binary_logloss: 0.286876\tvalid_2's binary_logloss: 0.289422\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252556\tvalid_1's binary_logloss: 0.253009\tvalid_2's binary_logloss: 0.253676\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.286347\tvalid_1's binary_logloss: 0.286961\tvalid_2's binary_logloss: 0.289891\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252637\tvalid_1's binary_logloss: 0.252963\tvalid_2's binary_logloss: 0.253634\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285124\tvalid_1's binary_logloss: 0.286084\tvalid_2's binary_logloss: 0.288404\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252467\tvalid_1's binary_logloss: 0.252956\tvalid_2's binary_logloss: 0.253369\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285962\tvalid_1's binary_logloss: 0.287028\tvalid_2's binary_logloss: 0.289597\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252613\tvalid_1's binary_logloss: 0.253028\tvalid_2's binary_logloss: 0.253678\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.285775\tvalid_1's binary_logloss: 0.286723\tvalid_2's binary_logloss: 0.289541\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252624\tvalid_1's binary_logloss: 0.252968\tvalid_2's binary_logloss: 0.253665\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.282476\tvalid_1's binary_logloss: 0.282736\tvalid_2's binary_logloss: 0.285159\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252673\tvalid_1's binary_logloss: 0.252847\tvalid_2's binary_logloss: 0.253373\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.280464\tvalid_1's binary_logloss: 0.280674\tvalid_2's binary_logloss: 0.283217\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252697\tvalid_1's binary_logloss: 0.252744\tvalid_2's binary_logloss: 0.253429\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.282909\tvalid_1's binary_logloss: 0.283209\tvalid_2's binary_logloss: 0.285581\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252541\tvalid_1's binary_logloss: 0.252729\tvalid_2's binary_logloss: 0.253258\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283871\tvalid_1's binary_logloss: 0.284584\tvalid_2's binary_logloss: 0.286907\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252655\tvalid_1's binary_logloss: 0.252927\tvalid_2's binary_logloss: 0.253358\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284763\tvalid_1's binary_logloss: 0.285279\tvalid_2's binary_logloss: 0.287867\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252644\tvalid_1's binary_logloss: 0.252839\tvalid_2's binary_logloss: 0.253398\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284157\tvalid_1's binary_logloss: 0.284789\tvalid_2's binary_logloss: 0.287248\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252606\tvalid_1's binary_logloss: 0.252938\tvalid_2's binary_logloss: 0.253433\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284157\tvalid_1's binary_logloss: 0.284789\tvalid_2's binary_logloss: 0.287248\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252606\tvalid_1's binary_logloss: 0.252938\tvalid_2's binary_logloss: 0.253433\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.272396\tvalid_1's binary_logloss: 0.271103\tvalid_2's binary_logloss: 0.274984\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.252978\tvalid_1's binary_logloss: 0.252402\tvalid_2's binary_logloss: 0.253938\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.282789\tvalid_1's binary_logloss: 0.283353\tvalid_2's binary_logloss: 0.285612\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252609\tvalid_1's binary_logloss: 0.252746\tvalid_2's binary_logloss: 0.253194\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283502\tvalid_1's binary_logloss: 0.283328\tvalid_2's binary_logloss: 0.285907\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.25298\tvalid_1's binary_logloss: 0.252942\tvalid_2's binary_logloss: 0.253384\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.282925\tvalid_1's binary_logloss: 0.283487\tvalid_2's binary_logloss: 0.285555\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252546\tvalid_1's binary_logloss: 0.252807\tvalid_2's binary_logloss: 0.25317\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283058\tvalid_1's binary_logloss: 0.283662\tvalid_2's binary_logloss: 0.285595\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252625\tvalid_1's binary_logloss: 0.252763\tvalid_2's binary_logloss: 0.253156\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283424\tvalid_1's binary_logloss: 0.284124\tvalid_2's binary_logloss: 0.28642\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.25255\tvalid_1's binary_logloss: 0.252823\tvalid_2's binary_logloss: 0.253228\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283287\tvalid_1's binary_logloss: 0.283733\tvalid_2's binary_logloss: 0.285913\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252782\tvalid_1's binary_logloss: 0.252903\tvalid_2's binary_logloss: 0.253271\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283999\tvalid_1's binary_logloss: 0.284049\tvalid_2's binary_logloss: 0.286217\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.252814\tvalid_1's binary_logloss: 0.253073\tvalid_2's binary_logloss: 0.253399\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283242\tvalid_1's binary_logloss: 0.283417\tvalid_2's binary_logloss: 0.285851\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252727\tvalid_1's binary_logloss: 0.252805\tvalid_2's binary_logloss: 0.253286\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283673\tvalid_1's binary_logloss: 0.283695\tvalid_2's binary_logloss: 0.286216\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252794\tvalid_1's binary_logloss: 0.252959\tvalid_2's binary_logloss: 0.253465\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283383\tvalid_1's binary_logloss: 0.28394\tvalid_2's binary_logloss: 0.286023\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252624\tvalid_1's binary_logloss: 0.252957\tvalid_2's binary_logloss: 0.253198\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284942\tvalid_1's binary_logloss: 0.285273\tvalid_2's binary_logloss: 0.287522\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.253093\tvalid_1's binary_logloss: 0.25333\tvalid_2's binary_logloss: 0.253892\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.287339\tvalid_1's binary_logloss: 0.287673\tvalid_2's binary_logloss: 0.289973\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's binary_logloss: 0.253361\tvalid_1's binary_logloss: 0.253611\tvalid_2's binary_logloss: 0.254013\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.288882\tvalid_1's binary_logloss: 0.289217\tvalid_2's binary_logloss: 0.29188\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's binary_logloss: 0.253005\tvalid_1's binary_logloss: 0.253394\tvalid_2's binary_logloss: 0.253794\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283698\tvalid_1's binary_logloss: 0.283993\tvalid_2's binary_logloss: 0.286129\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283699\tvalid_1's binary_logloss: 0.283994\tvalid_2's binary_logloss: 0.286129\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283064\tvalid_1's binary_logloss: 0.28329\tvalid_2's binary_logloss: 0.285341\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252801\tvalid_1's binary_logloss: 0.252925\tvalid_2's binary_logloss: 0.253186\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283698\tvalid_1's binary_logloss: 0.283994\tvalid_2's binary_logloss: 0.286129\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.28381\tvalid_1's binary_logloss: 0.283987\tvalid_2's binary_logloss: 0.286161\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252814\tvalid_1's binary_logloss: 0.252937\tvalid_2's binary_logloss: 0.2532\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283362\tvalid_1's binary_logloss: 0.28359\tvalid_2's binary_logloss: 0.28566\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252801\tvalid_1's binary_logloss: 0.252926\tvalid_2's binary_logloss: 0.253186\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283504\tvalid_1's binary_logloss: 0.283768\tvalid_2's binary_logloss: 0.285874\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252771\tvalid_1's binary_logloss: 0.252897\tvalid_2's binary_logloss: 0.253152\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283698\tvalid_1's binary_logloss: 0.283993\tvalid_2's binary_logloss: 0.286128\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283698\tvalid_1's binary_logloss: 0.283993\tvalid_2's binary_logloss: 0.286129\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283699\tvalid_1's binary_logloss: 0.283993\tvalid_2's binary_logloss: 0.286128\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283698\tvalid_1's binary_logloss: 0.283993\tvalid_2's binary_logloss: 0.286128\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.284209\tvalid_1's binary_logloss: 0.284445\tvalid_2's binary_logloss: 0.2868\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252766\tvalid_1's binary_logloss: 0.252891\tvalid_2's binary_logloss: 0.253154\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283207\tvalid_1's binary_logloss: 0.283308\tvalid_2's binary_logloss: 0.285705\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252661\tvalid_1's binary_logloss: 0.252808\tvalid_2's binary_logloss: 0.253168\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283073\tvalid_1's binary_logloss: 0.283094\tvalid_2's binary_logloss: 0.285347\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252739\tvalid_1's binary_logloss: 0.252796\tvalid_2's binary_logloss: 0.253132\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283483\tvalid_1's binary_logloss: 0.283868\tvalid_2's binary_logloss: 0.286018\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.252746\tvalid_1's binary_logloss: 0.252892\tvalid_2's binary_logloss: 0.253131\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283151\tvalid_1's binary_logloss: 0.28331\tvalid_2's binary_logloss: 0.285457\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283151\tvalid_1's binary_logloss: 0.28331\tvalid_2's binary_logloss: 0.285457\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283151\tvalid_1's binary_logloss: 0.28331\tvalid_2's binary_logloss: 0.285457\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283151\tvalid_1's binary_logloss: 0.28331\tvalid_2's binary_logloss: 0.285457\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283151\tvalid_1's binary_logloss: 0.28331\tvalid_2's binary_logloss: 0.285457\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.283079\tvalid_1's binary_logloss: 0.283249\tvalid_2's binary_logloss: 0.285303\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.2528\tvalid_1's binary_logloss: 0.252769\tvalid_2's binary_logloss: 0.253092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "lgb_clf = lightgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    categorical_feature=['shopper', 'product', 'category', 'coupon', 'coupon_in_same_category'],\n",
    "    valid_sets=[dval0, dval1, dval2],\n",
    "    verbose_eval=100,\n",
    "    early_stopping_rounds=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01854805, 0.01983229, 0.01854805, ..., 0.01918106, 0.02008953,\n       0.56972616])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prediction = lgb_clf.predict(cv_dict['X_test'][3], num_iteration=lgb_clf.best_iteration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Loading from pickle - prediction\n",
    "with open(os.getcwd() + \"/../data/pickle/pred.pickle\", 'rb') as f:\n",
    "  prediction =  pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load Data From Pickle\n",
    "\n",
    "with open(os.getcwd() + \"/../data/pickle/cv_dict_01.pickle\", 'rb') as f:\n",
    "  cv_dict =  pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(\n",
    "    y_true = cv_dict['y_test'][3],\n",
    "    y_score = prediction\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "# Loading from pickle - best_param\n",
    "with open(os.getcwd() + \"/../data/pickle/best_param.pickle\", 'rb') as f:\n",
    "  best_param =  pickle.load(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 5.024548095870188e-06, 'lambda_l2': 7.715874633155568, 'num_leaves': 37, 'feature_fraction': 0.4, 'bagging_fraction': 0.6190040709189294, 'bagging_freq': 5, 'min_child_samples': 20, 'categorical_column': [0, 1, 2, 105, 111]}\n",
      "  Accuracy = 0.9424730857826296\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: binary_logloss\n",
      "    verbosity: -1\n",
      "    boosting_type: gbdt\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 5.024548095870188e-06\n",
      "    lambda_l2: 7.715874633155568\n",
      "    num_leaves: 37\n",
      "    feature_fraction: 0.4\n",
      "    bagging_fraction: 0.6190040709189294\n",
      "    bagging_freq: 5\n",
      "    min_child_samples: 20\n",
      "    categorical_column: [0, 1, 2, 105, 111]\n"
     ]
    }
   ],
   "source": [
    "# best_params = lgb_clf.params\n",
    "print(\"Best params:\", best_param)\n",
    "print(\"  Accuracy = {}\".format(AUC))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_param.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKWx32kLAPxQ"
   },
   "source": [
    "# Prediction and Revenue Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwuSYI3m_K1h"
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xE6VKvuovPGo"
   },
   "outputs": [],
   "source": [
    "# train-test-split\r\n",
    "data.train_test_split(89, list(range(50)))\r\n",
    "\r\n",
    "# data add categories \r\n",
    "data.add_categories()\r\n",
    "data.create_feature_dict()\r\n",
    "X_train = data._make_full_table(data.baskets_train, data.coupons_train)\r\n",
    "X_test = data._make_full_table(data.baskets_test, data.coupons_test)\r\n",
    "\r\n",
    "X_train = data._merge_features(X_train, data.feature_dict)\r\n",
    "X_test = data._merge_features(X_test, data.feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "5PoslMy6HYUS",
    "outputId": "ec401ccf-1898-406f-e6bd-51e1898ee125"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNdd93i2fDj+19JCuE+Coj4",
   "collapsed_sections": [
    "psMpyT8ssu6E"
   ],
   "include_colab_link": true,
   "mount_file_id": "1n9Y-hoyoG6YpbLwHbiRKopbA4L2d2GAq",
   "name": "train_cv.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}